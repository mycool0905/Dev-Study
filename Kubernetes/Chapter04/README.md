# Chapter04


## 레플리케이션


### 레플리케이션에 관해서

`파드(Pod)`는 배포 가능한 기본 단위이다. 그렇지만 수동으로 안정적인 상태로 유지되게 관리하는 것은 쉽지 않다. 그래서 __쿠버네티스에서는 파드를 직접 생성하는 일 없이 여러가지 리소스를 이용해 파드를 관리할 수 있도록 한다__. `레플리케이션컨트롤러` 또는 `디플로이먼트`와 같은 유형의 리소스가 그 역할을 한다.


## 파드를 안정적으로 유지하기

일단 레플리케이션을 알아보기 전에 `라이브니스 프로브`에 대해서 알아본다.

### 라이브니스 프로브(liveness probe)

쿠버네티스는 `라이브니스 프로브(liveness probe)`를 통해 컨테이너가 살아 있는지 확인할 수 있다. 파드의 스펙에 각 컨테이너의 라이브니스 프로브를 지정할 수 있다. 쿠버네티스는 주기적으로 프로브를 실행하고 프로브가 실패할 경우 컨테이너를 다시 시작한다.

- 쿠버네티스의 세 가지 컨테이너 프로브 실행 메커니즘
  + `HTTP GET 프로브`: 지정한 IP 주소, 포트, 경로에 HTTP GET 요청을 수행한다. 프로브가 응답을 수신하고 응답 코드가 오류(HTTP STATUS: 4xx, 5xx)를 나타내지 않는 경우에 프로브가 성공했다고 간주한다. 서버가 오류 응답 코드를 반환하거나 전혀 응답하지 않으면 프로브가 실패한 것으로 간주돼 컨테이너를 다시 시작한다.
  + `TCP 소켓 프로브`: 컨테이너의 지정된 포트에 TCP 연결을 시도한다. 연결에 성공하면 프로브가 성공한 것이고, 그렇지 않으면 컨테이너가 다시 시작된다.
  + `Exec 프로브`: 컨테이너 내의 임의의 명령을 실행하고 명령의 종료 상태 코드를 확인한다. 상태 코드가 0이면 프로브가 성공한 것이다. 모든 다른 코드는 실패로 간주된다.
  

기존 kubia 이미지에서 억지로 실패하게 만드는 이미지인 `luksa/kubia-unhealthy`를 이용해 실습 가능하다. (5번의 Request를 받으면 애플리케이션은 HTTP STATUS 500을 반환하기 시작한다.)

#### kubia-liveness-probe.yaml
```
apiVersion: v1
kind: Pod
metadata:
  name: kubia-liveness
spec:
  containers:
  - image: luksa/kubia-unhealthy     // 약간 문제가 있는 애플리케이션
    name: kubia
    livenessProbe:
      httpGet:                       // HTTP GET을 수행하는 라이브니스 프로브
        path: /                      // HTTP 요청 경로
        port: 8080                   // 프로브가 연결해야 하는 네트워크 포트
```

이 파드 디스크립터는 쿠버네티스가 주기적으로 "/" 경로와 8080포트에 HTTP GET을 요청해서 컨테이너가 정상 동작하는지 확인하도록 httpGet 라이브니스 프로브를 정의한다. 이런 요청은 컨테이너가 실행되는 즉시 시작된다.

- ```$ kubectl logs <pod name> --previous```
  + 이전 컨테이너가 종료된 이유를 파악하기 위해 현재 컨테이너의 로그 대신 이전 컨테이너의 로그를 보기
- ```$ kubectl describe po <pod name>```
  + 여기서 보면 다시 시작된 횟수와 컨테이너가 재생성된 이유를 볼 수 있다.

![image](https://user-images.githubusercontent.com/43199318/112426455-5450b000-8d7b-11eb-9b61-d5368ede6001.png)

![image](https://user-images.githubusercontent.com/43199318/112426507-63cff900-8d7b-11eb-85cc-74bbc5946c92.png)

위에 적혀 있듯이, 컨테이너가 종료되면 완전히 새로운 컨테이너가 생성된다. 동일한 컨테이너가 다시 시작되는 것이 아니다.

#### 라이브니스 프로브의 추가 속성

![image](https://user-images.githubusercontent.com/43199318/112426702-bc06fb00-8d7b-11eb-88df-17bef64abcd2.png)

- 지연(delay): delay=0s, 컨테이너가 시작된 후 바로 프로브가 시작된다.
- 제한 시간(timeout): timeout=1s, 컨테이너가 1초 안에 응답해야 한다.
- 기간(period): period=10s, 컨테이너는 10초마다 프로브를 수행한다.
- 실패 횟수(failure): #failure=3, 프로브가 3번 연속 실패하면 컨테이너가 다시 시작된다.


#### 초기 지연을 추가한 라이브니스 프로브: kubia-liveness-probe-initial-delay.yaml
``` yaml
livenessProbe:
  httpGet:
    path: /
    port: 8080
  initialDelaySeconds: 15       // 첫 번째 프로브 실행까지 15초를 대기한다.
```

초기 지연을 설정하지 않으면 프로브는 컨테이너가 시작되자마자 프로브를 시작한다. 이 경우 대부분 애플리케이션이 요청을 받을 준비가 돼 있지 않기 때문에 프로브가 실패한다. 실패 횟수가 실패 임곗값을 초과하면 요청을 올바르게 응답하기 전에 컨테이너가 다시 시작된다. __애플리케이션 시작 시간을 고려해 초기 지연 설정을 꼭 해야한다는 점을 명심해야한다__.

#### 효과적인 라이브니스 프로브
1. 특정한 라이브니스 프로브를 위한 API를 설계하여 특정 URL 경로에 요청하도록 할 수 있다.(예:/health)
2. 애플리케이션 내부만 체크하도록 한다.(예: 프론트엔드 웹서버의 라이브니스 프로브는 웹서버가 백엔드 데이터베이스에 연결할 수 없을 때 실패를 반환하면 안된다. 근본적인 원인이 데이터베이스 자체에 있을 수 있다.)
3. 라이브니스 프로브는 너무 많은 연산 리소스를 사용해서는 안되고, 완료하는 데 너무 오래 걸리지 않아야 한다. 기본적으로 프로브는 비교적 자주 실행되며 1초 내에 완료돼야 한다. (너무 많은 일을 하는 프로브는 컨테이너의 속도를 상당히 느려지게 만든다.)
4. 프로브에 재시도 루프를 구현하지 말고, 프로브 실패 임곗값을 설정해라.(#failure)


### 레플리케이션컨트롤러

